{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "이 노트북은 [케라스 창시자에게 배우는 딥러닝 2판](https://tensorflow.blog/kerasdl2/)의 예제 코드를 담고 있습니다.\n",
    "\n",
    "이 노트북은 텐서플로 2.8 버전에서 테스트했습니다.\n",
    "\n",
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a href=\"https://colab.research.google.com/github/rickiepark/deep-learning-with-python-2nd/blob/main/chapter05_fundamentals-of-ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# 머신 러닝의 기본 요소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 일반화: 머신 러닝의 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 과소적합과 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 잡음 섞인 훈련 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 불확실한 특성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 드문 특성과 가짜 상관관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**MNIST에 백색 잡음 픽셀과 0 픽셀을 추가하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "train_images_with_noise_channels = np.concatenate(\n",
    "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
    "\n",
    "train_images_with_zeros_channels = np.concatenate(\n",
    "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1568)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_with_noise_channels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**백색 잡음과 0을 추가한 MNIST 데이터에서 모델 훈련하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 06:01:04.258374: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.6309 - accuracy: 0.8121 - val_loss: 0.2789 - val_accuracy: 0.9140\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2530 - accuracy: 0.9208 - val_loss: 0.2704 - val_accuracy: 0.9162\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1655 - accuracy: 0.9487 - val_loss: 0.1654 - val_accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1182 - accuracy: 0.9633 - val_loss: 0.1321 - val_accuracy: 0.9632\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0865 - accuracy: 0.9725 - val_loss: 0.1435 - val_accuracy: 0.9585\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0628 - accuracy: 0.9797 - val_loss: 0.1250 - val_accuracy: 0.9653\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0484 - accuracy: 0.9841 - val_loss: 0.1319 - val_accuracy: 0.9654\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0353 - accuracy: 0.9882 - val_loss: 0.1337 - val_accuracy: 0.9675\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.1286 - val_accuracy: 0.9696\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.1728 - val_accuracy: 0.9593\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2843 - accuracy: 0.9175 - val_loss: 0.1618 - val_accuracy: 0.9512\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1192 - accuracy: 0.9641 - val_loss: 0.1028 - val_accuracy: 0.9708\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0780 - accuracy: 0.9769 - val_loss: 0.0894 - val_accuracy: 0.9737\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0556 - accuracy: 0.9833 - val_loss: 0.0843 - val_accuracy: 0.9740\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0429 - accuracy: 0.9871 - val_loss: 0.0790 - val_accuracy: 0.9763\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0316 - accuracy: 0.9913 - val_loss: 0.0801 - val_accuracy: 0.9763\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.0819 - val_accuracy: 0.9793\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.0854 - val_accuracy: 0.9786\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.0854 - val_accuracy: 0.9793\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 0.0904 - val_accuracy: 0.9791\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "history_noise = model.fit(\n",
    "    train_images_with_noise_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)\n",
    "\n",
    "model = get_model()\n",
    "history_zeros = model.fit(\n",
    "    train_images_with_zeros_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**검증 정확도 비교 그래프 그리기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
    "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, val_acc_noise, \"b-\",\n",
    "         label=\"Validation accuracy with noise channels\")\n",
    "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
    "         label=\"Validation accuracy with zeros channels\")\n",
    "plt.title(\"Effect of noise channels on validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 딥러닝에서 일반화의 본질"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**랜덤하게 섞은 레이블로 MNIST 모델 훈련하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3173 - accuracy: 0.1044 - val_loss: 2.3068 - val_accuracy: 0.1095\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2995 - accuracy: 0.1183 - val_loss: 2.3133 - val_accuracy: 0.1042\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2899 - accuracy: 0.1320 - val_loss: 2.3219 - val_accuracy: 0.1021\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2753 - accuracy: 0.1427 - val_loss: 2.3322 - val_accuracy: 0.1016\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.2565 - accuracy: 0.1551 - val_loss: 2.3369 - val_accuracy: 0.1041\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.2345 - accuracy: 0.1726 - val_loss: 2.3527 - val_accuracy: 0.1017\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 2.2081 - accuracy: 0.1897 - val_loss: 2.3686 - val_accuracy: 0.1051\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.1809 - accuracy: 0.2012 - val_loss: 2.3865 - val_accuracy: 0.1028\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.1488 - accuracy: 0.2189 - val_loss: 2.4064 - val_accuracy: 0.1007\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.1183 - accuracy: 0.2361 - val_loss: 2.4301 - val_accuracy: 0.1054\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.0832 - accuracy: 0.2524 - val_loss: 2.4564 - val_accuracy: 0.1014\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.0498 - accuracy: 0.2672 - val_loss: 2.4817 - val_accuracy: 0.1039\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.0158 - accuracy: 0.2817 - val_loss: 2.5202 - val_accuracy: 0.1023\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.9803 - accuracy: 0.2978 - val_loss: 2.5423 - val_accuracy: 0.1029\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.9442 - accuracy: 0.3123 - val_loss: 2.5642 - val_accuracy: 0.1003\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.9100 - accuracy: 0.3257 - val_loss: 2.6118 - val_accuracy: 0.1023\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.8757 - accuracy: 0.3392 - val_loss: 2.6423 - val_accuracy: 0.1021\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.8407 - accuracy: 0.3543 - val_loss: 2.6853 - val_accuracy: 0.1012\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.8063 - accuracy: 0.3674 - val_loss: 2.7312 - val_accuracy: 0.0993\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.7745 - accuracy: 0.3781 - val_loss: 2.7509 - val_accuracy: 0.1007\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.7404 - accuracy: 0.3935 - val_loss: 2.8029 - val_accuracy: 0.0992\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.7110 - accuracy: 0.4040 - val_loss: 2.8249 - val_accuracy: 0.1012\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.6782 - accuracy: 0.4173 - val_loss: 2.8635 - val_accuracy: 0.1016\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.6488 - accuracy: 0.4279 - val_loss: 2.9038 - val_accuracy: 0.1037\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.6179 - accuracy: 0.4404 - val_loss: 2.9717 - val_accuracy: 0.1007\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 1.5879 - accuracy: 0.4542 - val_loss: 2.9952 - val_accuracy: 0.1034\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5598 - accuracy: 0.4635 - val_loss: 3.0233 - val_accuracy: 0.1022\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.5321 - accuracy: 0.4745 - val_loss: 3.0949 - val_accuracy: 0.1020\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 1.5061 - accuracy: 0.4823 - val_loss: 3.1246 - val_accuracy: 0.1012\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.4781 - accuracy: 0.4952 - val_loss: 3.1599 - val_accuracy: 0.1007\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4529 - accuracy: 0.5027 - val_loss: 3.2234 - val_accuracy: 0.1043\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.4266 - accuracy: 0.5144 - val_loss: 3.2677 - val_accuracy: 0.1002\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.4011 - accuracy: 0.5232 - val_loss: 3.3070 - val_accuracy: 0.1049\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.3785 - accuracy: 0.5322 - val_loss: 3.3782 - val_accuracy: 0.0997\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.3532 - accuracy: 0.5401 - val_loss: 3.3936 - val_accuracy: 0.1020\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.3301 - accuracy: 0.5472 - val_loss: 3.4560 - val_accuracy: 0.1005\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 1.3051 - accuracy: 0.5584 - val_loss: 3.5002 - val_accuracy: 0.1004\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 1.2848 - accuracy: 0.5634 - val_loss: 3.5664 - val_accuracy: 0.0991\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.2615 - accuracy: 0.5751 - val_loss: 3.6180 - val_accuracy: 0.1033\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.2430 - accuracy: 0.5801 - val_loss: 3.6496 - val_accuracy: 0.1039\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.2209 - accuracy: 0.5882 - val_loss: 3.7038 - val_accuracy: 0.1017\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.2011 - accuracy: 0.5953 - val_loss: 3.7946 - val_accuracy: 0.1026\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.1803 - accuracy: 0.6024 - val_loss: 3.8261 - val_accuracy: 0.1006\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 1.1614 - accuracy: 0.6085 - val_loss: 3.8652 - val_accuracy: 0.1016\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.1405 - accuracy: 0.6154 - val_loss: 3.9209 - val_accuracy: 0.1036\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 1.1202 - accuracy: 0.6240 - val_loss: 3.9765 - val_accuracy: 0.1001\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.1027 - accuracy: 0.6299 - val_loss: 4.0303 - val_accuracy: 0.1060\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.0835 - accuracy: 0.6380 - val_loss: 4.1208 - val_accuracy: 0.1018\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.0666 - accuracy: 0.6434 - val_loss: 4.1393 - val_accuracy: 0.1022\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.0500 - accuracy: 0.6478 - val_loss: 4.1607 - val_accuracy: 0.0990\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.0321 - accuracy: 0.6551 - val_loss: 4.2402 - val_accuracy: 0.1005\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.0158 - accuracy: 0.6625 - val_loss: 4.2891 - val_accuracy: 0.0986\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9983 - accuracy: 0.6673 - val_loss: 4.3611 - val_accuracy: 0.1002\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9830 - accuracy: 0.6732 - val_loss: 4.4277 - val_accuracy: 0.1041\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9699 - accuracy: 0.6768 - val_loss: 4.4937 - val_accuracy: 0.0990\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9538 - accuracy: 0.6837 - val_loss: 4.5655 - val_accuracy: 0.0969\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9358 - accuracy: 0.6907 - val_loss: 4.5910 - val_accuracy: 0.0954\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9222 - accuracy: 0.6943 - val_loss: 4.6564 - val_accuracy: 0.0995\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.9077 - accuracy: 0.7000 - val_loss: 4.7254 - val_accuracy: 0.1022\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.8930 - accuracy: 0.7044 - val_loss: 4.7680 - val_accuracy: 0.1037\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.8786 - accuracy: 0.7088 - val_loss: 4.8277 - val_accuracy: 0.1002\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.8624 - accuracy: 0.7169 - val_loss: 4.8970 - val_accuracy: 0.0989\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.8498 - accuracy: 0.7184 - val_loss: 4.9557 - val_accuracy: 0.1001\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.8361 - accuracy: 0.7238 - val_loss: 4.9978 - val_accuracy: 0.0991\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.8235 - accuracy: 0.7290 - val_loss: 5.0678 - val_accuracy: 0.1013\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.8106 - accuracy: 0.7329 - val_loss: 5.1666 - val_accuracy: 0.1004\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.7982 - accuracy: 0.7387 - val_loss: 5.1882 - val_accuracy: 0.0999\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7873 - accuracy: 0.7415 - val_loss: 5.2774 - val_accuracy: 0.0988\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7756 - accuracy: 0.7464 - val_loss: 5.3148 - val_accuracy: 0.0975\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7619 - accuracy: 0.7522 - val_loss: 5.3871 - val_accuracy: 0.0996\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7494 - accuracy: 0.7551 - val_loss: 5.4361 - val_accuracy: 0.1012\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7394 - accuracy: 0.7599 - val_loss: 5.5045 - val_accuracy: 0.1001\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7275 - accuracy: 0.7620 - val_loss: 5.5665 - val_accuracy: 0.1016\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7155 - accuracy: 0.7665 - val_loss: 5.6479 - val_accuracy: 0.1016\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.7065 - accuracy: 0.7681 - val_loss: 5.6902 - val_accuracy: 0.1018\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6937 - accuracy: 0.7740 - val_loss: 5.7135 - val_accuracy: 0.1007\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6820 - accuracy: 0.7790 - val_loss: 5.8151 - val_accuracy: 0.1022\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6718 - accuracy: 0.7813 - val_loss: 5.8923 - val_accuracy: 0.1004\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6621 - accuracy: 0.7841 - val_loss: 5.9766 - val_accuracy: 0.0983\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6522 - accuracy: 0.7902 - val_loss: 6.0459 - val_accuracy: 0.1024\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6434 - accuracy: 0.7905 - val_loss: 6.0982 - val_accuracy: 0.1016\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6323 - accuracy: 0.7944 - val_loss: 6.1574 - val_accuracy: 0.0998\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6230 - accuracy: 0.7981 - val_loss: 6.2147 - val_accuracy: 0.1028\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6134 - accuracy: 0.8044 - val_loss: 6.2887 - val_accuracy: 0.1018\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6060 - accuracy: 0.8051 - val_loss: 6.3780 - val_accuracy: 0.1032\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5967 - accuracy: 0.8061 - val_loss: 6.4081 - val_accuracy: 0.1009\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5880 - accuracy: 0.8093 - val_loss: 6.4498 - val_accuracy: 0.1051\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5763 - accuracy: 0.8140 - val_loss: 6.5423 - val_accuracy: 0.1026\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5687 - accuracy: 0.8174 - val_loss: 6.6400 - val_accuracy: 0.1002\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5619 - accuracy: 0.8190 - val_loss: 6.6726 - val_accuracy: 0.1013\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5561 - accuracy: 0.8209 - val_loss: 6.7160 - val_accuracy: 0.0995\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5429 - accuracy: 0.8273 - val_loss: 6.7923 - val_accuracy: 0.0997\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5367 - accuracy: 0.8287 - val_loss: 6.8978 - val_accuracy: 0.0999\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.5264 - accuracy: 0.8321 - val_loss: 7.0156 - val_accuracy: 0.1028\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5222 - accuracy: 0.8342 - val_loss: 7.0426 - val_accuracy: 0.1019\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5130 - accuracy: 0.8370 - val_loss: 7.1054 - val_accuracy: 0.0986\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5042 - accuracy: 0.8391 - val_loss: 7.2101 - val_accuracy: 0.0972\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4989 - accuracy: 0.8405 - val_loss: 7.2444 - val_accuracy: 0.0975\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4909 - accuracy: 0.8438 - val_loss: 7.3166 - val_accuracy: 0.1013\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4836 - accuracy: 0.8459 - val_loss: 7.4102 - val_accuracy: 0.1004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda4f3b6d90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "random_train_labels = train_labels[:]\n",
    "np.random.shuffle(random_train_labels)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, random_train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 매니폴드 가설"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 일반화의 원천인 보간"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 딥러닝이 작동하는 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 가장 중요한 훈련 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 머신 러닝 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 훈련, 검증, 테스트 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 단순 홀드아웃 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### K-겹 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 셔플링을 사용한 반복 K-겹 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 상식 수준의 기준점을 넘기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 평가에 대해 유념해야 할 점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 훈련 성능 향상하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 경사 하강법의 핵심 파라미터 튜닝하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**잘못된 높은 학습률로 MNIST 모델 훈련하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 864.5463 - accuracy: 0.4204 - val_loss: 2.0885 - val_accuracy: 0.2504\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 3.9584 - accuracy: 0.2538 - val_loss: 2.2037 - val_accuracy: 0.2064\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.8090 - accuracy: 0.2112 - val_loss: 2.9223 - val_accuracy: 0.2238\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.5907 - accuracy: 0.2327 - val_loss: 2.0428 - val_accuracy: 0.2383\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.6024 - accuracy: 0.2487 - val_loss: 2.5173 - val_accuracy: 0.2293\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.7019 - accuracy: 0.2658 - val_loss: 3.7475 - val_accuracy: 0.2871\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.6650 - accuracy: 0.2824 - val_loss: 2.1500 - val_accuracy: 0.3058\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.5495 - accuracy: 0.3114 - val_loss: 1.9372 - val_accuracy: 0.2990\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.6121 - accuracy: 0.2949 - val_loss: 2.5996 - val_accuracy: 0.2651\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.6738 - accuracy: 0.3047 - val_loss: 2.2377 - val_accuracy: 0.2432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda316fcf10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**같은 모델을 적절한 학습률로 훈련하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 0.3582 - accuracy: 0.9111 - val_loss: 0.1782 - val_accuracy: 0.9544\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1400 - accuracy: 0.9641 - val_loss: 0.1446 - val_accuracy: 0.9658\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1143 - accuracy: 0.9729 - val_loss: 0.1970 - val_accuracy: 0.9615\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1051 - accuracy: 0.9775 - val_loss: 0.1987 - val_accuracy: 0.9688\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0913 - accuracy: 0.9816 - val_loss: 0.2091 - val_accuracy: 0.9691\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0809 - accuracy: 0.9840 - val_loss: 0.2684 - val_accuracy: 0.9689\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0792 - accuracy: 0.9853 - val_loss: 0.2632 - val_accuracy: 0.9732\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0734 - accuracy: 0.9870 - val_loss: 0.3128 - val_accuracy: 0.9701\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0589 - accuracy: 0.9897 - val_loss: 0.3305 - val_accuracy: 0.9708\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0638 - accuracy: 0.9893 - val_loss: 0.3433 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda43babfd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 구조에 대해 더 나은 가정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 용량 늘리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**MNIST 데이터를 사용한 간단한 로지스틱 회귀 모델**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6807 - accuracy: 0.8317 - val_loss: 0.3630 - val_accuracy: 0.8993\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3518 - accuracy: 0.9031 - val_loss: 0.3095 - val_accuracy: 0.9147\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.9122 - val_loss: 0.2916 - val_accuracy: 0.9196\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2992 - accuracy: 0.9173 - val_loss: 0.2851 - val_accuracy: 0.9176\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2897 - accuracy: 0.9197 - val_loss: 0.2765 - val_accuracy: 0.9237\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2827 - accuracy: 0.9212 - val_loss: 0.2720 - val_accuracy: 0.9267\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2781 - accuracy: 0.9227 - val_loss: 0.2708 - val_accuracy: 0.9262\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2745 - accuracy: 0.9238 - val_loss: 0.2684 - val_accuracy: 0.9270\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2711 - accuracy: 0.9250 - val_loss: 0.2659 - val_accuracy: 0.9283\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2689 - accuracy: 0.9251 - val_loss: 0.2655 - val_accuracy: 0.9274\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.9264 - val_loss: 0.2656 - val_accuracy: 0.9281\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2646 - accuracy: 0.9273 - val_loss: 0.2627 - val_accuracy: 0.9289\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2630 - accuracy: 0.9269 - val_loss: 0.2633 - val_accuracy: 0.9289\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2617 - accuracy: 0.9278 - val_loss: 0.2614 - val_accuracy: 0.9309\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2603 - accuracy: 0.9285 - val_loss: 0.2617 - val_accuracy: 0.9301\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2590 - accuracy: 0.9293 - val_loss: 0.2624 - val_accuracy: 0.9291\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.9294 - val_loss: 0.2607 - val_accuracy: 0.9303\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2570 - accuracy: 0.9297 - val_loss: 0.2637 - val_accuracy: 0.9312\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2565 - accuracy: 0.9301 - val_loss: 0.2614 - val_accuracy: 0.9298\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2555 - accuracy: 0.9305 - val_loss: 0.2631 - val_accuracy: 0.9297\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_small_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = history_small_model.history[\"val_loss\"]\n",
    "epochs = range(1, 21)\n",
    "plt.plot(epochs, val_loss, \"b--\",\n",
    "         label=\"Validation loss\")\n",
    "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3548 - accuracy: 0.8989 - val_loss: 0.1857 - val_accuracy: 0.9485\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1611 - accuracy: 0.9517 - val_loss: 0.1329 - val_accuracy: 0.9606\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1141 - accuracy: 0.9664 - val_loss: 0.1121 - val_accuracy: 0.9667\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0880 - accuracy: 0.9735 - val_loss: 0.1038 - val_accuracy: 0.9697\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0705 - accuracy: 0.9785 - val_loss: 0.1022 - val_accuracy: 0.9714\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9825 - val_loss: 0.0979 - val_accuracy: 0.9712\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0476 - accuracy: 0.9852 - val_loss: 0.1046 - val_accuracy: 0.9729\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0390 - accuracy: 0.9881 - val_loss: 0.1021 - val_accuracy: 0.9732\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0327 - accuracy: 0.9904 - val_loss: 0.1032 - val_accuracy: 0.9747\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 0.1031 - val_accuracy: 0.9748\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.1076 - val_accuracy: 0.9750\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.1189 - val_accuracy: 0.9735\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.1076 - val_accuracy: 0.9771\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.1223 - val_accuracy: 0.9759\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.1344 - val_accuracy: 0.9725\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.1361 - val_accuracy: 0.9743\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1350 - val_accuracy: 0.9750\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1451 - val_accuracy: 0.9735\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.1436 - val_accuracy: 0.9754\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1622 - val_accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_large_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 일반화 성능 향상하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 데이터셋 큐레이션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 특성 공학"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 조기 종료 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 규제하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 네트워크 크기 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**원본 모델**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 06:08:06.806259: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 600000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 2s 53ms/step - loss: 0.5583 - accuracy: 0.7349 - val_loss: 0.4152 - val_accuracy: 0.8658\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.3334 - accuracy: 0.8959 - val_loss: 0.3370 - val_accuracy: 0.8722\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.2316 - accuracy: 0.9288 - val_loss: 0.3156 - val_accuracy: 0.8704\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1788 - accuracy: 0.9432 - val_loss: 0.2803 - val_accuracy: 0.8867\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.1438 - accuracy: 0.9553 - val_loss: 0.2895 - val_accuracy: 0.8847\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.1166 - accuracy: 0.9645 - val_loss: 0.3241 - val_accuracy: 0.8817\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0966 - accuracy: 0.9708 - val_loss: 0.3186 - val_accuracy: 0.8819\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0747 - accuracy: 0.9802 - val_loss: 0.3674 - val_accuracy: 0.8792\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0649 - accuracy: 0.9819 - val_loss: 0.3676 - val_accuracy: 0.8788\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0512 - accuracy: 0.9868 - val_loss: 0.3974 - val_accuracy: 0.8782\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0393 - accuracy: 0.9911 - val_loss: 0.4507 - val_accuracy: 0.8666\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0330 - accuracy: 0.9932 - val_loss: 0.4653 - val_accuracy: 0.8743\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0276 - accuracy: 0.9943 - val_loss: 0.4943 - val_accuracy: 0.8747\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0194 - accuracy: 0.9964 - val_loss: 0.5250 - val_accuracy: 0.8728\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0196 - accuracy: 0.9960 - val_loss: 0.5599 - val_accuracy: 0.8726\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0102 - accuracy: 0.9987 - val_loss: 0.5894 - val_accuracy: 0.8710\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 0.6287 - val_accuracy: 0.8708\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.6538 - val_accuracy: 0.8677\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.6934 - val_accuracy: 0.8684\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.7460 - val_accuracy: 0.8687\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "train_data = vectorize_sequences(train_data)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_original = model.fit(train_data, train_labels,\n",
    "                             epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**작은 용량의 모델**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 06:08:23.002536: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 600000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 2s 50ms/step - loss: 0.6102 - accuracy: 0.7357 - val_loss: 0.5276 - val_accuracy: 0.8339\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.4571 - accuracy: 0.8817 - val_loss: 0.4236 - val_accuracy: 0.8588\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.3550 - accuracy: 0.9025 - val_loss: 0.3575 - val_accuracy: 0.8793\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.2875 - accuracy: 0.9159 - val_loss: 0.3240 - val_accuracy: 0.8768\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.2425 - accuracy: 0.9271 - val_loss: 0.2934 - val_accuracy: 0.8892\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.2086 - accuracy: 0.9363 - val_loss: 0.2839 - val_accuracy: 0.8887\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1825 - accuracy: 0.9441 - val_loss: 0.2740 - val_accuracy: 0.8930\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1610 - accuracy: 0.9513 - val_loss: 0.2801 - val_accuracy: 0.8874\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1432 - accuracy: 0.9571 - val_loss: 0.2749 - val_accuracy: 0.8914\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1281 - accuracy: 0.9621 - val_loss: 0.2825 - val_accuracy: 0.8890\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.1149 - accuracy: 0.9670 - val_loss: 0.2858 - val_accuracy: 0.8900\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1032 - accuracy: 0.9705 - val_loss: 0.2948 - val_accuracy: 0.8880\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.0922 - accuracy: 0.9750 - val_loss: 0.3042 - val_accuracy: 0.8883\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0835 - accuracy: 0.9772 - val_loss: 0.3176 - val_accuracy: 0.8844\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0745 - accuracy: 0.9807 - val_loss: 0.3327 - val_accuracy: 0.8819\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0667 - accuracy: 0.9838 - val_loss: 0.3445 - val_accuracy: 0.8816\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0596 - accuracy: 0.9861 - val_loss: 0.3587 - val_accuracy: 0.8807\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0530 - accuracy: 0.9878 - val_loss: 0.3744 - val_accuracy: 0.8794\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0469 - accuracy: 0.9895 - val_loss: 0.3888 - val_accuracy: 0.8789\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0414 - accuracy: 0.9913 - val_loss: 0.4078 - val_accuracy: 0.8762\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_smaller_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**큰 용량의 모델**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 06:08:39.214137: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 600000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 6s 150ms/step - loss: 0.5602 - accuracy: 0.7523 - val_loss: 0.3069 - val_accuracy: 0.8823\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 3s 105ms/step - loss: 0.2433 - accuracy: 0.9059 - val_loss: 0.2695 - val_accuracy: 0.8935\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.1620 - accuracy: 0.9411 - val_loss: 0.3178 - val_accuracy: 0.8811\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 3s 107ms/step - loss: 0.0903 - accuracy: 0.9739 - val_loss: 0.3846 - val_accuracy: 0.8755\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.0974 - accuracy: 0.9755 - val_loss: 0.3148 - val_accuracy: 0.8811\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.0067 - accuracy: 0.9997 - val_loss: 0.5090 - val_accuracy: 0.8863\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 3s 118ms/step - loss: 8.1295e-04 - accuracy: 0.9999 - val_loss: 0.6112 - val_accuracy: 0.8839\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 3s 109ms/step - loss: 1.1569e-04 - accuracy: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.8839\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 2.0587e-05 - accuracy: 1.0000 - val_loss: 0.8230 - val_accuracy: 0.8819\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 4s 118ms/step - loss: 0.3718 - accuracy: 0.9817 - val_loss: 0.8002 - val_accuracy: 0.8577\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.7042 - val_accuracy: 0.8798\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 3.1784e-05 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8816\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 3s 107ms/step - loss: 1.4323e-05 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.8816\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 7.2266e-06 - accuracy: 1.0000 - val_loss: 0.7991 - val_accuracy: 0.8825\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 3s 106ms/step - loss: 3.2674e-06 - accuracy: 1.0000 - val_loss: 0.8748 - val_accuracy: 0.8826\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 1.2612e-06 - accuracy: 1.0000 - val_loss: 0.9523 - val_accuracy: 0.8821\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 4.6610e-07 - accuracy: 1.0000 - val_loss: 1.0402 - val_accuracy: 0.8817\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 1.7514e-07 - accuracy: 1.0000 - val_loss: 1.1086 - val_accuracy: 0.8816\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 7.4711e-08 - accuracy: 1.0000 - val_loss: 1.1657 - val_accuracy: 0.8819\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 3.6566e-08 - accuracy: 1.0000 - val_loss: 1.2086 - val_accuracy: 0.8819\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_larger_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 가중치 규제 추가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델에 L2 가중치 추가하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 06:09:45.646248: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 600000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 2s 48ms/step - loss: 0.5829 - accuracy: 0.7870 - val_loss: 0.4552 - val_accuracy: 0.8715\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 0.3873 - accuracy: 0.8965 - val_loss: 0.4027 - val_accuracy: 0.8699\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.3194 - accuracy: 0.9145 - val_loss: 0.3937 - val_accuracy: 0.8683\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.2871 - accuracy: 0.9275 - val_loss: 0.3595 - val_accuracy: 0.8866\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.2704 - accuracy: 0.9335 - val_loss: 0.3574 - val_accuracy: 0.8869\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.2545 - accuracy: 0.9392 - val_loss: 0.3664 - val_accuracy: 0.8829\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.2435 - accuracy: 0.9455 - val_loss: 0.3734 - val_accuracy: 0.8816\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.2360 - accuracy: 0.9471 - val_loss: 0.3825 - val_accuracy: 0.8786\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.2291 - accuracy: 0.9488 - val_loss: 0.3770 - val_accuracy: 0.8810\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.2282 - accuracy: 0.9504 - val_loss: 0.3835 - val_accuracy: 0.8803\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.2165 - accuracy: 0.9563 - val_loss: 0.3903 - val_accuracy: 0.8781\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.2150 - accuracy: 0.9535 - val_loss: 0.4394 - val_accuracy: 0.8643\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.2145 - accuracy: 0.9552 - val_loss: 0.3992 - val_accuracy: 0.8758\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.2087 - accuracy: 0.9581 - val_loss: 0.4115 - val_accuracy: 0.8760\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.2037 - accuracy: 0.9589 - val_loss: 0.4306 - val_accuracy: 0.8694\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.2027 - accuracy: 0.9601 - val_loss: 0.4054 - val_accuracy: 0.8764\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.2008 - accuracy: 0.9598 - val_loss: 0.4183 - val_accuracy: 0.8740\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1980 - accuracy: 0.9617 - val_loss: 0.4122 - val_accuracy: 0.8778\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1914 - accuracy: 0.9629 - val_loss: 0.4412 - val_accuracy: 0.8718\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1998 - accuracy: 0.9576 - val_loss: 0.4179 - val_accuracy: 0.8770\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_l2_reg = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**케라스에서 사용할 수 있는 가중치 규제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.regularizers.L1L2 at 0x7fd9a2053b80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "regularizers.l1(0.001)\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 드롭아웃 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**IMDB 모델에 드롭아웃 추가하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 06:10:00.536333: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 600000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 2s 47ms/step - loss: 0.6451 - accuracy: 0.6151 - val_loss: 0.5485 - val_accuracy: 0.7754\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.5379 - accuracy: 0.7553 - val_loss: 0.4662 - val_accuracy: 0.8721\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.4668 - accuracy: 0.8147 - val_loss: 0.3946 - val_accuracy: 0.8826\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.4075 - accuracy: 0.8542 - val_loss: 0.3587 - val_accuracy: 0.8811\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.3580 - accuracy: 0.8818 - val_loss: 0.3193 - val_accuracy: 0.8893\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.3185 - accuracy: 0.9031 - val_loss: 0.3038 - val_accuracy: 0.8921\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.2771 - accuracy: 0.9161 - val_loss: 0.2920 - val_accuracy: 0.8887\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.2547 - accuracy: 0.9281 - val_loss: 0.2929 - val_accuracy: 0.8890\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.2269 - accuracy: 0.9361 - val_loss: 0.3097 - val_accuracy: 0.8903\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.2038 - accuracy: 0.9458 - val_loss: 0.3093 - val_accuracy: 0.8905\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1848 - accuracy: 0.9490 - val_loss: 0.3251 - val_accuracy: 0.8882\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1629 - accuracy: 0.9546 - val_loss: 0.3796 - val_accuracy: 0.8825\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1538 - accuracy: 0.9580 - val_loss: 0.3673 - val_accuracy: 0.8883\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1444 - accuracy: 0.9606 - val_loss: 0.3599 - val_accuracy: 0.8849\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1249 - accuracy: 0.9661 - val_loss: 0.3967 - val_accuracy: 0.8874\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.1164 - accuracy: 0.9693 - val_loss: 0.4393 - val_accuracy: 0.8863\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.1088 - accuracy: 0.9697 - val_loss: 0.4698 - val_accuracy: 0.8837\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1010 - accuracy: 0.9732 - val_loss: 0.5441 - val_accuracy: 0.8792\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.0928 - accuracy: 0.9745 - val_loss: 0.5324 - val_accuracy: 0.8851\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0862 - accuracy: 0.9772 - val_loss: 0.5024 - val_accuracy: 0.8846\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_dropout = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 요약"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter05_fundamentals-of-ml.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
