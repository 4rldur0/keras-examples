{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "이 노트북은 [케라스 창시자에게 배우는 딥러닝 2판](https://tensorflow.blog/kerasdl2/)의 예제 코드를 담고 있습니다.\n",
    "\n",
    "<table align=\"left\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <a href=\"https://colab.research.google.com/github/rickiepark/deep-learning-with-python-2nd/blob/main/chapter05_fundamentals-of-ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# 머신 러닝의 기본 요소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 일반화: 머신 러닝의 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 과소적합과 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 잡음 섞인 훈련 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 불확실한 특성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 드문 특성과 가짜 상관관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**MNIST에 백색 잡음 픽셀과 0 픽셀을 추가하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:01:24.254476Z",
     "iopub.status.busy": "2022-05-21T01:01:24.253958Z",
     "iopub.status.idle": "2022-05-21T01:01:27.373051Z",
     "shell.execute_reply": "2022-05-21T01:01:27.372074Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "train_images_with_noise_channels = np.concatenate(\n",
    "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
    "\n",
    "train_images_with_zeros_channels = np.concatenate(\n",
    "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T01:01:27.377455Z",
     "iopub.status.busy": "2022-05-21T01:01:27.376945Z",
     "iopub.status.idle": "2022-05-21T01:01:27.388938Z",
     "shell.execute_reply": "2022-05-21T01:01:27.387917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1568)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_with_noise_channels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**백색 잡음과 0을 추가한 MNIST 데이터에서 모델 훈련하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:01:27.392783Z",
     "iopub.status.busy": "2022-05-21T01:01:27.392444Z",
     "iopub.status.idle": "2022-05-21T01:02:25.502977Z",
     "shell.execute_reply": "2022-05-21T01:02:25.502078Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 01:01:27.403814: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6158 - accuracy: 0.8106 - val_loss: 0.2610 - val_accuracy: 0.9242\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.2563 - accuracy: 0.9197 - val_loss: 0.2508 - val_accuracy: 0.9234\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1684 - accuracy: 0.9475 - val_loss: 0.1487 - val_accuracy: 0.9558\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1220 - accuracy: 0.9618 - val_loss: 0.1407 - val_accuracy: 0.9590\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0892 - accuracy: 0.9716 - val_loss: 0.1349 - val_accuracy: 0.9604\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0652 - accuracy: 0.9792 - val_loss: 0.1354 - val_accuracy: 0.9617\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0499 - accuracy: 0.9840 - val_loss: 0.1431 - val_accuracy: 0.9605\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0385 - accuracy: 0.9875 - val_loss: 0.1437 - val_accuracy: 0.9621\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0269 - accuracy: 0.9911 - val_loss: 0.1251 - val_accuracy: 0.9667\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 0.1289 - val_accuracy: 0.9698\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2923 - accuracy: 0.9164 - val_loss: 0.1690 - val_accuracy: 0.9523\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1185 - accuracy: 0.9651 - val_loss: 0.1025 - val_accuracy: 0.9703\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0776 - accuracy: 0.9773 - val_loss: 0.0879 - val_accuracy: 0.9735\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0557 - accuracy: 0.9830 - val_loss: 0.1043 - val_accuracy: 0.9693\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0409 - accuracy: 0.9880 - val_loss: 0.0855 - val_accuracy: 0.9754\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.0794 - val_accuracy: 0.9779\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.0824 - val_accuracy: 0.9776\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 0.0801 - val_accuracy: 0.9803\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.0948 - val_accuracy: 0.9758\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0943 - val_accuracy: 0.9770\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "history_noise = model.fit(\n",
    "    train_images_with_noise_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)\n",
    "\n",
    "model = get_model()\n",
    "history_zeros = model.fit(\n",
    "    train_images_with_zeros_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**검증 정확도 비교 그래프 그리기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:02:25.507068Z",
     "iopub.status.busy": "2022-05-21T01:02:25.506610Z",
     "iopub.status.idle": "2022-05-21T01:02:26.352048Z",
     "shell.execute_reply": "2022-05-21T01:02:26.351089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
    "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, val_acc_noise, \"b-\",\n",
    "         label=\"Validation accuracy with noise channels\")\n",
    "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
    "         label=\"Validation accuracy with zeros channels\")\n",
    "plt.title(\"Effect of noise channels on validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 딥러닝에서 일반화의 본질"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**랜덤하게 섞은 레이블로 MNIST 모델 훈련하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:02:26.358294Z",
     "iopub.status.busy": "2022-05-21T01:02:26.357787Z",
     "iopub.status.idle": "2022-05-21T01:05:33.171731Z",
     "shell.execute_reply": "2022-05-21T01:05:33.170427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3168 - accuracy: 0.1006 - val_loss: 2.3052 - val_accuracy: 0.1036\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2997 - accuracy: 0.1165 - val_loss: 2.3132 - val_accuracy: 0.0977\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2906 - accuracy: 0.1282 - val_loss: 2.3238 - val_accuracy: 0.1044\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2766 - accuracy: 0.1395 - val_loss: 2.3324 - val_accuracy: 0.0997\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2583 - accuracy: 0.1554 - val_loss: 2.3478 - val_accuracy: 0.0956\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2378 - accuracy: 0.1703 - val_loss: 2.3524 - val_accuracy: 0.0959\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.2135 - accuracy: 0.1830 - val_loss: 2.3730 - val_accuracy: 0.0981\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.1860 - accuracy: 0.1985 - val_loss: 2.3880 - val_accuracy: 0.0983\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.1555 - accuracy: 0.2160 - val_loss: 2.4163 - val_accuracy: 0.0944\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.1241 - accuracy: 0.2326 - val_loss: 2.4338 - val_accuracy: 0.0967\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0914 - accuracy: 0.2464 - val_loss: 2.4510 - val_accuracy: 0.0972\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0580 - accuracy: 0.2631 - val_loss: 2.4928 - val_accuracy: 0.0980\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.0237 - accuracy: 0.2800 - val_loss: 2.5235 - val_accuracy: 0.0961\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9915 - accuracy: 0.2898 - val_loss: 2.5548 - val_accuracy: 0.1008\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9547 - accuracy: 0.3075 - val_loss: 2.5729 - val_accuracy: 0.0966\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.9209 - accuracy: 0.3210 - val_loss: 2.6071 - val_accuracy: 0.1023\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8880 - accuracy: 0.3368 - val_loss: 2.6480 - val_accuracy: 0.0971\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8530 - accuracy: 0.3513 - val_loss: 2.6867 - val_accuracy: 0.1005\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.8197 - accuracy: 0.3613 - val_loss: 2.7010 - val_accuracy: 0.1001\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7868 - accuracy: 0.3744 - val_loss: 2.7421 - val_accuracy: 0.0999\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7557 - accuracy: 0.3866 - val_loss: 2.7935 - val_accuracy: 0.1000\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.7238 - accuracy: 0.3992 - val_loss: 2.8317 - val_accuracy: 0.0993\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6947 - accuracy: 0.4115 - val_loss: 2.8658 - val_accuracy: 0.0984\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6633 - accuracy: 0.4217 - val_loss: 2.9173 - val_accuracy: 0.1005\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6361 - accuracy: 0.4348 - val_loss: 2.9411 - val_accuracy: 0.1032\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.6056 - accuracy: 0.4460 - val_loss: 2.9679 - val_accuracy: 0.1019\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5780 - accuracy: 0.4568 - val_loss: 3.0255 - val_accuracy: 0.1008\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5505 - accuracy: 0.4664 - val_loss: 3.0763 - val_accuracy: 0.1008\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.5241 - accuracy: 0.4756 - val_loss: 3.1273 - val_accuracy: 0.0983\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4976 - accuracy: 0.4846 - val_loss: 3.1695 - val_accuracy: 0.0978\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4749 - accuracy: 0.4960 - val_loss: 3.2259 - val_accuracy: 0.1002\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4481 - accuracy: 0.5039 - val_loss: 3.2744 - val_accuracy: 0.0973\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4236 - accuracy: 0.5159 - val_loss: 3.3085 - val_accuracy: 0.0986\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.4004 - accuracy: 0.5226 - val_loss: 3.3565 - val_accuracy: 0.0982\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.3760 - accuracy: 0.5320 - val_loss: 3.4180 - val_accuracy: 0.1010\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 1.3523 - accuracy: 0.5403 - val_loss: 3.4647 - val_accuracy: 0.0999\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3329 - accuracy: 0.5468 - val_loss: 3.4934 - val_accuracy: 0.0977\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.3085 - accuracy: 0.5578 - val_loss: 3.5460 - val_accuracy: 0.1017\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2900 - accuracy: 0.5632 - val_loss: 3.6003 - val_accuracy: 0.1004\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2662 - accuracy: 0.5730 - val_loss: 3.6458 - val_accuracy: 0.1011\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2445 - accuracy: 0.5798 - val_loss: 3.6896 - val_accuracy: 0.0985\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2258 - accuracy: 0.5875 - val_loss: 3.7366 - val_accuracy: 0.0960\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.2065 - accuracy: 0.5929 - val_loss: 3.8049 - val_accuracy: 0.1002\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1885 - accuracy: 0.5982 - val_loss: 3.8606 - val_accuracy: 0.0960\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1676 - accuracy: 0.6076 - val_loss: 3.9283 - val_accuracy: 0.0988\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1481 - accuracy: 0.6129 - val_loss: 3.9672 - val_accuracy: 0.0954\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1314 - accuracy: 0.6190 - val_loss: 4.0161 - val_accuracy: 0.1022\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.1143 - accuracy: 0.6254 - val_loss: 4.0863 - val_accuracy: 0.0975\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0947 - accuracy: 0.6315 - val_loss: 4.1256 - val_accuracy: 0.0971\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0773 - accuracy: 0.6410 - val_loss: 4.1848 - val_accuracy: 0.0978\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0622 - accuracy: 0.6453 - val_loss: 4.2469 - val_accuracy: 0.0978\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0454 - accuracy: 0.6495 - val_loss: 4.2907 - val_accuracy: 0.0952\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0286 - accuracy: 0.6560 - val_loss: 4.3398 - val_accuracy: 0.0959\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 1.0131 - accuracy: 0.6634 - val_loss: 4.4089 - val_accuracy: 0.1000\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9967 - accuracy: 0.6671 - val_loss: 4.4581 - val_accuracy: 0.0969\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9821 - accuracy: 0.6725 - val_loss: 4.5322 - val_accuracy: 0.0956\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9667 - accuracy: 0.6778 - val_loss: 4.5838 - val_accuracy: 0.0981\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9521 - accuracy: 0.6832 - val_loss: 4.6271 - val_accuracy: 0.0972\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9382 - accuracy: 0.6890 - val_loss: 4.7203 - val_accuracy: 0.0984\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9237 - accuracy: 0.6931 - val_loss: 4.8355 - val_accuracy: 0.1000\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9122 - accuracy: 0.6973 - val_loss: 4.8052 - val_accuracy: 0.0987\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8969 - accuracy: 0.7045 - val_loss: 4.8760 - val_accuracy: 0.0985\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8834 - accuracy: 0.7072 - val_loss: 4.9346 - val_accuracy: 0.0979\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8703 - accuracy: 0.7113 - val_loss: 4.9811 - val_accuracy: 0.0993\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8583 - accuracy: 0.7154 - val_loss: 5.0912 - val_accuracy: 0.0967\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8455 - accuracy: 0.7193 - val_loss: 5.1504 - val_accuracy: 0.0968\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8343 - accuracy: 0.7249 - val_loss: 5.1722 - val_accuracy: 0.0988\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8208 - accuracy: 0.7296 - val_loss: 5.2758 - val_accuracy: 0.0952\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.8073 - accuracy: 0.7338 - val_loss: 5.3533 - val_accuracy: 0.0966\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7975 - accuracy: 0.7370 - val_loss: 5.4020 - val_accuracy: 0.0982\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7860 - accuracy: 0.7411 - val_loss: 5.4116 - val_accuracy: 0.0976\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7716 - accuracy: 0.7477 - val_loss: 5.5060 - val_accuracy: 0.0997\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7606 - accuracy: 0.7517 - val_loss: 5.5366 - val_accuracy: 0.0998\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7482 - accuracy: 0.7541 - val_loss: 5.6590 - val_accuracy: 0.0970\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7379 - accuracy: 0.7585 - val_loss: 5.7195 - val_accuracy: 0.0995\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7295 - accuracy: 0.7606 - val_loss: 5.8005 - val_accuracy: 0.0993\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7175 - accuracy: 0.7649 - val_loss: 5.8446 - val_accuracy: 0.0978\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.7074 - accuracy: 0.7663 - val_loss: 5.9220 - val_accuracy: 0.0985\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6974 - accuracy: 0.7701 - val_loss: 5.9727 - val_accuracy: 0.1002\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6862 - accuracy: 0.7759 - val_loss: 6.0277 - val_accuracy: 0.1001\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6776 - accuracy: 0.7791 - val_loss: 6.0833 - val_accuracy: 0.0986\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6666 - accuracy: 0.7836 - val_loss: 6.1938 - val_accuracy: 0.0991\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6587 - accuracy: 0.7871 - val_loss: 6.2276 - val_accuracy: 0.0976\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6484 - accuracy: 0.7881 - val_loss: 6.2831 - val_accuracy: 0.0989\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6395 - accuracy: 0.7907 - val_loss: 6.3865 - val_accuracy: 0.0997\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6313 - accuracy: 0.7946 - val_loss: 6.4912 - val_accuracy: 0.0995\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6211 - accuracy: 0.7984 - val_loss: 6.5104 - val_accuracy: 0.0976\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6115 - accuracy: 0.8022 - val_loss: 6.5586 - val_accuracy: 0.0978\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6036 - accuracy: 0.8046 - val_loss: 6.6031 - val_accuracy: 0.1049\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5943 - accuracy: 0.8075 - val_loss: 6.6853 - val_accuracy: 0.0979\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5872 - accuracy: 0.8108 - val_loss: 6.7872 - val_accuracy: 0.0982\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5779 - accuracy: 0.8131 - val_loss: 6.8696 - val_accuracy: 0.0991\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5689 - accuracy: 0.8153 - val_loss: 6.9161 - val_accuracy: 0.1002\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5610 - accuracy: 0.8181 - val_loss: 6.9820 - val_accuracy: 0.1009\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5534 - accuracy: 0.8209 - val_loss: 7.0527 - val_accuracy: 0.1023\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5465 - accuracy: 0.8239 - val_loss: 7.1350 - val_accuracy: 0.1005\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5374 - accuracy: 0.8277 - val_loss: 7.1628 - val_accuracy: 0.1006\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5322 - accuracy: 0.8289 - val_loss: 7.3048 - val_accuracy: 0.0958\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5235 - accuracy: 0.8316 - val_loss: 7.3475 - val_accuracy: 0.1023\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5157 - accuracy: 0.8339 - val_loss: 7.4391 - val_accuracy: 0.1016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0110103cf8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "random_train_labels = train_labels[:]\n",
    "np.random.shuffle(random_train_labels)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, random_train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 매니폴드 가설"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 일반화의 원천인 보간"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 딥러닝이 작동하는 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 가장 중요한 훈련 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 머신 러닝 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 훈련, 검증, 테스트 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 단순 홀드아웃 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### K-겹 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 셔플링을 사용한 반복 K-겹 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 상식 수준의 기준점을 넘기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 평가에 대해 유념해야 할 점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 훈련 성능 향상하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 경사 하강법의 핵심 파라미터 튜닝하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**잘못된 높은 학습률로 MNIST 모델 훈련하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:05:33.177460Z",
     "iopub.status.busy": "2022-05-21T01:05:33.177117Z",
     "iopub.status.idle": "2022-05-21T01:05:52.585061Z",
     "shell.execute_reply": "2022-05-21T01:05:52.584241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 956.4675 - accuracy: 0.3946 - val_loss: 3.5492 - val_accuracy: 0.2813\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 4.6012 - accuracy: 0.2683 - val_loss: 2.1531 - val_accuracy: 0.2711\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.9923 - accuracy: 0.2559 - val_loss: 2.1568 - val_accuracy: 0.2036\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.7545 - accuracy: 0.2514 - val_loss: 2.9839 - val_accuracy: 0.3231\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 3.2284 - accuracy: 0.2866 - val_loss: 2.3702 - val_accuracy: 0.2873\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.5103 - accuracy: 0.2761 - val_loss: 2.1773 - val_accuracy: 0.2202\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.4951 - accuracy: 0.2595 - val_loss: 2.8390 - val_accuracy: 0.2891\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.4925 - accuracy: 0.2729 - val_loss: 2.1782 - val_accuracy: 0.2317\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.8699 - accuracy: 0.2906 - val_loss: 2.7469 - val_accuracy: 0.2726\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.5351 - accuracy: 0.2940 - val_loss: 2.0229 - val_accuracy: 0.2466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0112c54b70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**같은 모델을 적절한 학습률로 훈련하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:05:52.588549Z",
     "iopub.status.busy": "2022-05-21T01:05:52.588260Z",
     "iopub.status.idle": "2022-05-21T01:06:11.526008Z",
     "shell.execute_reply": "2022-05-21T01:06:11.525112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3735 - accuracy: 0.9098 - val_loss: 0.1643 - val_accuracy: 0.9557\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1400 - accuracy: 0.9640 - val_loss: 0.1392 - val_accuracy: 0.9669\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1149 - accuracy: 0.9730 - val_loss: 0.1867 - val_accuracy: 0.9610\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0993 - accuracy: 0.9778 - val_loss: 0.1815 - val_accuracy: 0.9715\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0848 - accuracy: 0.9815 - val_loss: 0.2341 - val_accuracy: 0.9691\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0806 - accuracy: 0.9834 - val_loss: 0.2015 - val_accuracy: 0.9727\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0719 - accuracy: 0.9865 - val_loss: 0.2717 - val_accuracy: 0.9685\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0691 - accuracy: 0.9877 - val_loss: 0.2729 - val_accuracy: 0.9725\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0628 - accuracy: 0.9889 - val_loss: 0.2601 - val_accuracy: 0.9737\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0565 - accuracy: 0.9903 - val_loss: 0.3517 - val_accuracy: 0.9668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0112b120b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 구조에 대해 더 나은 가정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 용량 늘리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**MNIST 데이터를 사용한 간단한 로지스틱 회귀 모델**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:06:11.530131Z",
     "iopub.status.busy": "2022-05-21T01:06:11.529560Z",
     "iopub.status.idle": "2022-05-21T01:06:25.955536Z",
     "shell.execute_reply": "2022-05-21T01:06:25.954654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.6708 - accuracy: 0.8349 - val_loss: 0.3596 - val_accuracy: 0.9038\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3522 - accuracy: 0.9026 - val_loss: 0.3089 - val_accuracy: 0.9152\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3162 - accuracy: 0.9117 - val_loss: 0.2901 - val_accuracy: 0.9185\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2998 - accuracy: 0.9163 - val_loss: 0.2812 - val_accuracy: 0.9196\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2903 - accuracy: 0.9187 - val_loss: 0.2749 - val_accuracy: 0.9236\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2835 - accuracy: 0.9206 - val_loss: 0.2741 - val_accuracy: 0.9244\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2782 - accuracy: 0.9227 - val_loss: 0.2694 - val_accuracy: 0.9246\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2743 - accuracy: 0.9235 - val_loss: 0.2668 - val_accuracy: 0.9261\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2717 - accuracy: 0.9245 - val_loss: 0.2640 - val_accuracy: 0.9283\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2691 - accuracy: 0.9253 - val_loss: 0.2647 - val_accuracy: 0.9278\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2673 - accuracy: 0.9256 - val_loss: 0.2628 - val_accuracy: 0.9281\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2650 - accuracy: 0.9270 - val_loss: 0.2633 - val_accuracy: 0.9286\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2633 - accuracy: 0.9273 - val_loss: 0.2617 - val_accuracy: 0.9301\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2619 - accuracy: 0.9279 - val_loss: 0.2622 - val_accuracy: 0.9293\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2602 - accuracy: 0.9284 - val_loss: 0.2625 - val_accuracy: 0.9291\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2594 - accuracy: 0.9284 - val_loss: 0.2609 - val_accuracy: 0.9303\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.9288 - val_loss: 0.2607 - val_accuracy: 0.9299\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2573 - accuracy: 0.9298 - val_loss: 0.2597 - val_accuracy: 0.9307\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2566 - accuracy: 0.9296 - val_loss: 0.2610 - val_accuracy: 0.9299\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.9301 - val_loss: 0.2597 - val_accuracy: 0.9310\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_small_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:06:25.959685Z",
     "iopub.status.busy": "2022-05-21T01:06:25.959399Z",
     "iopub.status.idle": "2022-05-21T01:06:26.277516Z",
     "shell.execute_reply": "2022-05-21T01:06:26.276506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = history_small_model.history[\"val_loss\"]\n",
    "epochs = range(1, 21)\n",
    "plt.plot(epochs, val_loss, \"b--\",\n",
    "         label=\"Validation loss\")\n",
    "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:06:26.281161Z",
     "iopub.status.busy": "2022-05-21T01:06:26.280863Z",
     "iopub.status.idle": "2022-05-21T01:06:48.235589Z",
     "shell.execute_reply": "2022-05-21T01:06:48.234644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 2s 3ms/step - loss: 0.3613 - accuracy: 0.8980 - val_loss: 0.2050 - val_accuracy: 0.9401\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1603 - accuracy: 0.9523 - val_loss: 0.1302 - val_accuracy: 0.9623\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1145 - accuracy: 0.9659 - val_loss: 0.1135 - val_accuracy: 0.9668\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0876 - accuracy: 0.9737 - val_loss: 0.1044 - val_accuracy: 0.9691\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0710 - accuracy: 0.9789 - val_loss: 0.1364 - val_accuracy: 0.9583\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0581 - accuracy: 0.9821 - val_loss: 0.1086 - val_accuracy: 0.9691\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.9853 - val_loss: 0.0935 - val_accuracy: 0.9746\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0404 - accuracy: 0.9875 - val_loss: 0.0910 - val_accuracy: 0.9737\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0329 - accuracy: 0.9896 - val_loss: 0.0982 - val_accuracy: 0.9753\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9914 - val_loss: 0.0983 - val_accuracy: 0.9759\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.1004 - val_accuracy: 0.9768\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.1194 - val_accuracy: 0.9718\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.1086 - val_accuracy: 0.9748\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.1157 - val_accuracy: 0.9734\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.1185 - val_accuracy: 0.9755\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.1231 - val_accuracy: 0.9749\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1310 - val_accuracy: 0.9748\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1318 - val_accuracy: 0.9745\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1499 - val_accuracy: 0.9730\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1514 - val_accuracy: 0.9741\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_large_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 일반화 성능 향상하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 데이터셋 큐레이션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 특성 공학"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 조기 종료 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 규제하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 네트워크 크기 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**원본 모델**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:06:48.240327Z",
     "iopub.status.busy": "2022-05-21T01:06:48.239635Z",
     "iopub.status.idle": "2022-05-21T01:07:01.599335Z",
     "shell.execute_reply": "2022-05-21T01:07:01.598428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.5206 - accuracy: 0.8014 - val_loss: 0.3950 - val_accuracy: 0.8709\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3199 - accuracy: 0.9005 - val_loss: 0.3420 - val_accuracy: 0.8611\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2366 - accuracy: 0.9255 - val_loss: 0.2835 - val_accuracy: 0.8899\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1868 - accuracy: 0.9394 - val_loss: 0.2920 - val_accuracy: 0.8825\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1540 - accuracy: 0.9509 - val_loss: 0.2746 - val_accuracy: 0.8888\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1266 - accuracy: 0.9601 - val_loss: 0.2858 - val_accuracy: 0.8865\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1038 - accuracy: 0.9691 - val_loss: 0.3048 - val_accuracy: 0.8850\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0884 - accuracy: 0.9741 - val_loss: 0.3194 - val_accuracy: 0.8835\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0726 - accuracy: 0.9804 - val_loss: 0.3452 - val_accuracy: 0.8813\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0631 - accuracy: 0.9839 - val_loss: 0.3652 - val_accuracy: 0.8809\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0503 - accuracy: 0.9883 - val_loss: 0.3973 - val_accuracy: 0.8764\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0421 - accuracy: 0.9905 - val_loss: 0.4161 - val_accuracy: 0.8781\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0333 - accuracy: 0.9932 - val_loss: 0.4492 - val_accuracy: 0.8744\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9943 - val_loss: 0.4943 - val_accuracy: 0.8691\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0218 - accuracy: 0.9966 - val_loss: 0.5404 - val_accuracy: 0.8673\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.5454 - val_accuracy: 0.8696\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9975 - val_loss: 0.5734 - val_accuracy: 0.8698\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0090 - accuracy: 0.9991 - val_loss: 0.6149 - val_accuracy: 0.8658\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.9987 - val_loss: 0.6541 - val_accuracy: 0.8644\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.7251 - val_accuracy: 0.8596\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "train_data = vectorize_sequences(train_data)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_original = model.fit(train_data, train_labels,\n",
    "                             epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**작은 용량의 모델**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:07:01.603485Z",
     "iopub.status.busy": "2022-05-21T01:07:01.603168Z",
     "iopub.status.idle": "2022-05-21T01:07:09.910749Z",
     "shell.execute_reply": "2022-05-21T01:07:09.909893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.6109 - accuracy: 0.7743 - val_loss: 0.5419 - val_accuracy: 0.8368\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4792 - accuracy: 0.8785 - val_loss: 0.4481 - val_accuracy: 0.8662\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3874 - accuracy: 0.9012 - val_loss: 0.3844 - val_accuracy: 0.8774\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3210 - accuracy: 0.9144 - val_loss: 0.3397 - val_accuracy: 0.8843\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2718 - accuracy: 0.9254 - val_loss: 0.3123 - val_accuracy: 0.8873\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2343 - accuracy: 0.9337 - val_loss: 0.2949 - val_accuracy: 0.8897\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2059 - accuracy: 0.9420 - val_loss: 0.2812 - val_accuracy: 0.8921\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1818 - accuracy: 0.9483 - val_loss: 0.2773 - val_accuracy: 0.8894\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1616 - accuracy: 0.9547 - val_loss: 0.2755 - val_accuracy: 0.8912\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1437 - accuracy: 0.9598 - val_loss: 0.2949 - val_accuracy: 0.8812\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1296 - accuracy: 0.9639 - val_loss: 0.2765 - val_accuracy: 0.8904\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1154 - accuracy: 0.9699 - val_loss: 0.2822 - val_accuracy: 0.8879\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.1034 - accuracy: 0.9728 - val_loss: 0.2890 - val_accuracy: 0.8870\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0926 - accuracy: 0.9763 - val_loss: 0.3013 - val_accuracy: 0.8849\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0820 - accuracy: 0.9802 - val_loss: 0.3065 - val_accuracy: 0.8828\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0733 - accuracy: 0.9830 - val_loss: 0.3187 - val_accuracy: 0.8826\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0650 - accuracy: 0.9860 - val_loss: 0.3290 - val_accuracy: 0.8816\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0578 - accuracy: 0.9881 - val_loss: 0.3416 - val_accuracy: 0.8807\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.0509 - accuracy: 0.9895 - val_loss: 0.3598 - val_accuracy: 0.8780\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0455 - accuracy: 0.9907 - val_loss: 0.3694 - val_accuracy: 0.8780\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_smaller_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**큰 용량의 모델**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:07:09.914619Z",
     "iopub.status.busy": "2022-05-21T01:07:09.914070Z",
     "iopub.status.idle": "2022-05-21T01:07:55.440909Z",
     "shell.execute_reply": "2022-05-21T01:07:55.439855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 3s 89ms/step - loss: 0.5415 - accuracy: 0.7588 - val_loss: 0.2896 - val_accuracy: 0.8829\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.2697 - accuracy: 0.8931 - val_loss: 0.2733 - val_accuracy: 0.8867\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.1415 - accuracy: 0.9493 - val_loss: 0.3534 - val_accuracy: 0.8785\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.0855 - accuracy: 0.9726 - val_loss: 0.5873 - val_accuracy: 0.8282\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.1175 - accuracy: 0.9763 - val_loss: 0.3404 - val_accuracy: 0.8861\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.4938 - val_accuracy: 0.8885\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 9.6325e-04 - accuracy: 0.9998 - val_loss: 0.5984 - val_accuracy: 0.8877\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 1.2871e-04 - accuracy: 1.0000 - val_loss: 0.7316 - val_accuracy: 0.8873\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 2.4239e-05 - accuracy: 1.0000 - val_loss: 0.8166 - val_accuracy: 0.8851\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 4.8460e-06 - accuracy: 1.0000 - val_loss: 0.9175 - val_accuracy: 0.8852\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 3s 89ms/step - loss: 1.2302e-06 - accuracy: 1.0000 - val_loss: 1.0019 - val_accuracy: 0.8851\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 3.7986e-07 - accuracy: 1.0000 - val_loss: 1.1047 - val_accuracy: 0.8860\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 1.3450e-07 - accuracy: 1.0000 - val_loss: 1.1699 - val_accuracy: 0.8857\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 5.3586e-08 - accuracy: 1.0000 - val_loss: 1.2033 - val_accuracy: 0.8851\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 2.9812e-08 - accuracy: 1.0000 - val_loss: 1.2375 - val_accuracy: 0.8850\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 2.0001e-08 - accuracy: 1.0000 - val_loss: 1.2630 - val_accuracy: 0.8851\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 1.4867e-08 - accuracy: 1.0000 - val_loss: 1.2777 - val_accuracy: 0.8851\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 1.1879e-08 - accuracy: 1.0000 - val_loss: 1.2938 - val_accuracy: 0.8850\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 9.8788e-09 - accuracy: 1.0000 - val_loss: 1.3059 - val_accuracy: 0.8850\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 8.4562e-09 - accuracy: 1.0000 - val_loss: 1.3161 - val_accuracy: 0.8850\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_larger_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 가중치 규제 추가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델에 L2 가중치 추가하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:07:55.445676Z",
     "iopub.status.busy": "2022-05-21T01:07:55.444826Z",
     "iopub.status.idle": "2022-05-21T01:08:04.225182Z",
     "shell.execute_reply": "2022-05-21T01:08:04.224432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.5787 - accuracy: 0.7929 - val_loss: 0.4689 - val_accuracy: 0.8470\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3892 - accuracy: 0.8927 - val_loss: 0.3838 - val_accuracy: 0.8838\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3288 - accuracy: 0.9137 - val_loss: 0.3636 - val_accuracy: 0.8872\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2975 - accuracy: 0.9272 - val_loss: 0.3631 - val_accuracy: 0.8860\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2766 - accuracy: 0.9333 - val_loss: 0.3683 - val_accuracy: 0.8821\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2708 - accuracy: 0.9329 - val_loss: 0.3644 - val_accuracy: 0.8845\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2529 - accuracy: 0.9429 - val_loss: 0.3637 - val_accuracy: 0.8837\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2508 - accuracy: 0.9409 - val_loss: 0.3676 - val_accuracy: 0.8827\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2435 - accuracy: 0.9427 - val_loss: 0.3712 - val_accuracy: 0.8803\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2384 - accuracy: 0.9460 - val_loss: 0.3746 - val_accuracy: 0.8792\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2348 - accuracy: 0.9480 - val_loss: 0.3924 - val_accuracy: 0.8755\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2235 - accuracy: 0.9518 - val_loss: 0.3952 - val_accuracy: 0.8740\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2253 - accuracy: 0.9510 - val_loss: 0.4122 - val_accuracy: 0.8720\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2218 - accuracy: 0.9525 - val_loss: 0.3898 - val_accuracy: 0.8790\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2218 - accuracy: 0.9511 - val_loss: 0.3932 - val_accuracy: 0.8804\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2151 - accuracy: 0.9548 - val_loss: 0.4375 - val_accuracy: 0.8680\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2113 - accuracy: 0.9569 - val_loss: 0.4685 - val_accuracy: 0.8522\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2129 - accuracy: 0.9544 - val_loss: 0.4060 - val_accuracy: 0.8748\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2139 - accuracy: 0.9545 - val_loss: 0.4045 - val_accuracy: 0.8762\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2047 - accuracy: 0.9593 - val_loss: 0.4253 - val_accuracy: 0.8715\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_l2_reg = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**케라스에서 사용할 수 있는 가중치 규제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:08:04.229728Z",
     "iopub.status.busy": "2022-05-21T01:08:04.228866Z",
     "iopub.status.idle": "2022-05-21T01:08:04.237099Z",
     "shell.execute_reply": "2022-05-21T01:08:04.235990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.regularizers.L1L2 at 0x7f01127f9b70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "regularizers.l1(0.001)\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 드롭아웃 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**IMDB 모델에 드롭아웃 추가하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2022-05-21T01:08:04.241161Z",
     "iopub.status.busy": "2022-05-21T01:08:04.240762Z",
     "iopub.status.idle": "2022-05-21T01:08:13.113623Z",
     "shell.execute_reply": "2022-05-21T01:08:13.112554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.6506 - accuracy: 0.6252 - val_loss: 0.5948 - val_accuracy: 0.6429\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.5570 - accuracy: 0.7669 - val_loss: 0.5365 - val_accuracy: 0.6993\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.4997 - accuracy: 0.8367 - val_loss: 0.4947 - val_accuracy: 0.8158\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4624 - accuracy: 0.8798 - val_loss: 0.4843 - val_accuracy: 0.8327\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4317 - accuracy: 0.9024 - val_loss: 0.4688 - val_accuracy: 0.8687\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.4090 - accuracy: 0.9189 - val_loss: 0.4877 - val_accuracy: 0.8551\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3827 - accuracy: 0.9296 - val_loss: 0.4758 - val_accuracy: 0.8653\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3632 - accuracy: 0.9375 - val_loss: 0.5131 - val_accuracy: 0.8581\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3495 - accuracy: 0.9441 - val_loss: 0.4777 - val_accuracy: 0.8677\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3322 - accuracy: 0.9480 - val_loss: 0.5052 - val_accuracy: 0.8635\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3157 - accuracy: 0.9542 - val_loss: 0.5703 - val_accuracy: 0.8582\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.3026 - accuracy: 0.9572 - val_loss: 0.5821 - val_accuracy: 0.8603\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2859 - accuracy: 0.9617 - val_loss: 0.5412 - val_accuracy: 0.8609\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2770 - accuracy: 0.9614 - val_loss: 0.6549 - val_accuracy: 0.8525\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2657 - accuracy: 0.9650 - val_loss: 0.6693 - val_accuracy: 0.8559\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2514 - accuracy: 0.9685 - val_loss: 0.6917 - val_accuracy: 0.8569\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2405 - accuracy: 0.9675 - val_loss: 0.7566 - val_accuracy: 0.8517\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2293 - accuracy: 0.9712 - val_loss: 0.7901 - val_accuracy: 0.8503\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.2183 - accuracy: 0.9717 - val_loss: 0.8234 - val_accuracy: 0.8511\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2115 - accuracy: 0.9743 - val_loss: 0.9100 - val_accuracy: 0.8491\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_dropout = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 요약"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter05_fundamentals-of-ml.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
